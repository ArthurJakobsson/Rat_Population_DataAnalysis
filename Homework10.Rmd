---
title: "36-315 Homework 10, Fall 2022"
author: "Alex Cheng"
date: "Due November 23, 2022 by 11:59pm"
output:
  pdf_document:
    toc: yes
  html_document:
    toc: yes
    toc_float: yes
    code_folding: show
urlcolor: blue
---

#  Homework 10:  Time Series and Final Project EDA

***General instructions for all assignments***: 

+ Use this file as the template for your submission. Be sure to write your name at the top of this page in the author section.

+ Please write out your answers in *italics* or **bold** to differentiate your answers from the problem statements. (However, your code does not needed to be italicized or bold, of course!)

+ For your homework submission, generate an .html file and an .Rmd file (named as: [AndrewID]-315-Homework10.Rmd -- e.g. "zbranson-315-Homework10.Rmd"). When you're done, submit it to Gradescope (the link to the course's Gradescope can be found on Canvas). Remember that Gradescope only accepts PDFs, so be sure to Knit to PDF (see Lab0). Alternatively, you can use [this online converter](https://cloudconvert.com/html-to-pdf) to convert your HTML file to a PDF. If you have trouble knitting to PDF, please contact the Head TA and Professor Branson.

+ Your file should contain the code to answer each question in its own code block. Your code should produce plots/output that will be automatically embedded in the PDF. **Before submitting your PDF, be sure that all of your code/plots are displayed.**

+ Each answer must be supported by written statements (unless otherwise specified). **Thus, even if you think your code output is self-explanatory, be sure to answer questions with written statements outside of code blocks.**

+ Although it's okay to discuss homework problems with other students, all of your homework (code, written answers, etc.) should be only your own. Instances of identical, nearly identical, or copied homework will be considered cheating and plagiarism. In other words, you must follow rules of academic integrity (as detailed in the syllabus).

***
***

##  Problem 1: EDA for Final Project (10pts)

For this problem, all you need to do is turn in one plot using the dataset your team chose for the final project. The plot can be any visual of your choice, but it must meet these three requirements:

+ At a minimum your graph must display three variables. (It can even display more, if you prefer.)
+ Be sure that your plot is appropriately titled and labeled such that it is clear what you are plotting.
+ Your graph should answer a question about your dataset that's unique among your teammates. Thus, all your teammates shouldn't make the same graph (or a graph of the same variables), and each of your graphs should answer a different question for the dataset. Thus, you'll need to discuss with your team about the plots you all plan to make (and more generally, how you will divide up the work for your final project). This is exactly why we did not have lab this week, so that you have more time to meet with your team and discuss.

```{r}
library(tidyverse)
library(gridExtra)
rats = read.csv("Rat_Population_DataAnalysis/Raw/rats_condensed.csv")
rats = subset(rats, rats$Borough != "Unspecified")
```
```{r}
rats_fam = subset(rats, grepl("Family", rats$Location.Type, fixed = TRUE))
rats_fam$simple = ifelse(grepl("1-2", rats_fam$Location.Type, fixed = TRUE), "1-2 Family", "3+ Families")
rats_other = subset(rats, !grepl("Family", rats$Location.Type, fixed = TRUE))
rats_other = rats_other %>% group_by(Location.Type) %>% filter(n() > 300 )
family = ggplot(data = rats_fam, aes(x = Borough)) + 
geom_bar(aes(fill = simple)) + 
labs(
title = "Rat Sightings Count for Family Dwellings",
x = "Borough",
y = "Count",
fill = "Number of Families"
)
non_family = ggplot(data = rats_other, aes(x = Borough)) + 
geom_bar(aes(fill = Location.Type)) + 
labs(
title = "Rat Sightings Count for Non-Family Dwellings",
subtitle = "Must have at least 300 sightings per location type",
x = "Borough",
y = "Count",
fill = "Location Type"
)
grid.arrange(family, non_family, nrow = 2)
```

After you've made your plot, interpret the plot in 2-4 sentences and discuss why you think this plot is informative for the kind of questions you want to answer with your dataset.

**A big part of our discussion is exactly where the rats appear, so I thought dividing it up by boroughs, which will give me rough geographic locations, as well as type of building, specifically family vs non-family, will help me answer that question. One thing that was interesting to me was while we were very interested in the correlation between rats and restaurants, there are only 11 rat sightings near a restaurant, and it wasn't even able to make it onto the graph, which I think reflects the quality of health inspections in NYC. Furthermore, it is interesting that in the above graph, a big portion of rat sightings come from buildings with 3+ families, which may suggest a correlation between the number of people and the number of rats. In the graph, below, a large portion of the sightings, ignoring "Other", comes form commercial buildings, which intuitively does make sense.**

The best way to complete this question is to take a few days to think about your dataset (possiby discussing with your teammates) and make a few plots that you think are interesting, and then only submit your best plot for this question. You **should not** just try to make an arbitrary multivariate graph as quickly as possible to complete this problem, because if we think your graph/interpretation is not well-motivated given the goals of your project, we may deduct up to 7.5pts for this problem. After this homework, you should share your graph with your team, so you don't want to make a graph that you'd be embarrassed to show your teammates.

## Problem 2: Data Manipulation to Create Basic Time Series Plots (28 points)

In this homework, we'll use data from the [NYC Citi Bike](https://www.citibikenyc.com/) program. The NYC Citi Bike data is a tremendous resource; see [this page](https://www.citibikenyc.com/system-data) for details about the various datasets that are available. There are tons of data that we could work with here, and we're just going to work with a small subset. To ensure that no one has issues accessing very large raw data files, I already subsetted the data for you, such that you can load it here:
```{r, warning = F, message = F}
#loading the data
bikeData <- read.csv("https://raw.githubusercontent.com/zjbranson/315Fall2022/main/bikeData.csv")
```

a. (8pts) This dataset contains information about bike trips taken by individuals in New York City. The dataset contains time and geographic information (and we're going to focus on the time information). But before we dive into that, let's understand the demographics of the individuals in our dataset. There are three variables in the dataset related to demographics: `usertype`, `birth.year`, and `gender`. First, create a graph that you think best visualizes all three of these variables in a single graph. (Note: Using facets still counts as one graph.)

```{r}
ggplot(data = bikeData, aes(x = birth.year, y = as.factor(gender))) + 
geom_boxplot(aes(fill = usertype))  + 
scale_y_discrete(name = "Gender", labels = c("Unknown", "Male", "Female")) + 
labs(
title = "NYC Citi Bike Data",
x = "Birth Year",
fill = "User Type"
)
```

After you've made your graph, answer the following two questions:

+ In 1-3 sentences, use this graph to describe the subjects in this dataset in terms of `usertype`, `birth.year`, and `gender`. Note that you'll need to read the data documentation above to understand how the `gender` variable is coded.

**For male and female riders, the average birth year for customers is higher than that of subscribers. Not much can be said for the comparison between subscribers and customers of unknown gender, since the IQR for customers is virtually zero, so it is very hard to read the distribution.**

+ Based on your visualization, are there any aspects about the data that seem strange? State Yes or No, and explain in one sentence. If you say Yes, give a 1-2 sentence explanation as to why this strange phenomenon might be occurring in this dataset.

**There seems to be a lot of outliers - every boxplot is littered with a bunch of points outside of the IQR.**

(For most data analyses - including the final project - it is often useful to first visualize the types of subjects that are in your dataset before immediately diving into nuanced analyses about complex information like time and location data. So, this question is meant to give you some more practice with that.)

b. (10pts) Now we will explore time-varying aspects of the data. The variable `start.date` contains the day that someone began a bike trip. To utilize this variable, we first need to convert it to a `Date` variable. (By default, `start.date` is likely classified as a `character` variable.) The following code does this for you:
```{r, warning = F, message = F}
#  convert start.date variable to Date
library(tidyverse)
bikeData <- mutate(bikeData, start.date = as.Date(start.date, format ="%m/%d/%y"))
```

(Note that I had to use `%m/%d/%y` - instead of `%m/%d/%Y` used in the Lecture 20 `R` demo - because the date in `bikeData` is recorded with a *two-digit* year instead of a four-digit year. At first I thought about being sinister and asking you to figure out the format yourself, but I decided to save you some time.)

Now, for this part, create a new `data.frame` called `trips_per_day` that contains two columns:

+ `start.date`: All of the unique dates in `start.date` in the `bikeData` dataset.
+ `n_trips`: The number of trips that were made on each particular `start.date`.

For example, the following code shows you that 58 trips were made on January 1, 2019:
```{r}
sum(bikeData$start.date == "2019-01-01")
```
So, one of the rows of the dataset should have `start.date = "2019-01-01"` and `n_trips = 58`.

**Hint**: Use the `group_by()` and `summarize()` functions, which we've used a lot in this class.

```{r}
trips_per_day = bikeData %>% count(start.date)
colnames(trips_per_day)[2] = "n_trips"
#this was just easier for me
```

Now, using the dataset you created, plot the number of trips over time. Do this using `ggplot()` and `geom_line()`, with `n_trips` on the y-axis and `start.date` on the x-axis. Be sure the plot is appropriately titled and labeled.

```{r}
ggplot(data = trips_per_day, aes(x = start.date, y = n_trips)) + 
geom_line() + 
labs(
x = "Date",
y = "Number of Trips",
title = "Number of NYC Bike Trips per Day"
)
```

After you do this, describe the plot in 1-3 sentences, particularly in terms of global trends and seasonality. 

**There seems to be a seasonal spike in bike trips in the fall and a seasonal dip in the winter. Furthermore, there is a huge spike in trips in fall of 2020.**

c. (10pts) Now let's think back to the dataset you created in Part B. Each row should contain a day and the number of trips made on that day. But some of those trips were made by `usertype = "Customer"`, and some were made by `usertype = "Subscriber"`.

For this part, create a new dataset that breaks down `trips_per_day` (which you created in Part B) by `usertype`. Call this dataset `trips_per_day_usertype`. For example, the following code demonstrates that, among trips made on January 1, 2019, 7 were "customers" and 51 were "subscribers".

```{r}
table( subset(bikeData, start.date == "2019-01-01")$usertype )
```

Thus, one row of the `trips_per_day_usertype` dataset should have `start.date = "2019-01-01"`, `usertype = "Customer"`, and `n_trips = 7` and another row should have `start.date = "2019-01-01"`, `usertype = "Subscriber"`, and `n_trips = 51`.

**Hint**: Part B essentially asked you to `group_by()` the variable `start.date`. In this part, you need to `group_by()` `start.date` *and* `usertype`.

```{r}
trips_per_day_usertype = bikeData %>%
group_by(start.date, usertype) %>% tally()
colnames(trips_per_day_usertype)[3] = "n_trips"
```

After you've done this, using `trips_per_day_usertype`, create the same time series plot as Part B, but colored by `usertype`. In other words, your plot should show two time series: one for "customers" and one for "subscribers." When making your plot, set `alpha` to something less than 1 so you can more easily see both time series.

```{r}
ggplot(data = trips_per_day_usertype, aes(x = start.date, y = n_trips)) + 
geom_line(aes(color = usertype), alpha = 0.5) + 
labs(
x = "Date",
y = "Number of Trips",
title = "Number of NYC Bike Trips per Day",
color = "User Type"
)
```

After you've made your plot, compare and contrast the two time series in your plot in 1-3 sentences.

**The marginal count for subscribers is higher than that of customers for almost every day. Furthermore, they reflect each other in terms of overall trends, but it seems like subscribers have a lot more day-to-day variability in 2019, and less in 2020.**

***
***

##  Problem 3: Lags and Autocorrelation (20 points)

a. (8pts) In this problem we will explore autocorrelations, which are just the correlation of a time series with itself at different lags. Before making autocorrelation plots for the NYC bike data, let's start by looking at a totally random, made up time series: 
```{r}
rand_ts <- rnorm(1000)
```
This is just 1000 random numbers from a Normal(0, 1) distribution; thus, this is simulating a time series at 1000 time points.

Using the `acf()` function, create an autocorrelation plot of `rand_ts`. The `acf()` function by default computes the autocorrelation for lags 0 through 30. (In general, this default value will depend on the length of the time series.) **When making your autocorrelation plot for this question**, display the autocorrelation for lags 0 through 500 instead. (**Hint**: Check the help documentation for `acf` to see how to change the maximum lag calculated.)

```{r}
acf(rand_ts, plot = TRUE, lag.max = 500)
```

After you've made the plot, answer the following questions:

+ According to the confidence intervals in your plot, are any of the autocorrelations significantly different from zero? If so, which lags appear to have autocorrelations significantly different from 0?

**The autocorrelation at 0 is significantly different from zero. There are also some autocorrelations around the 100 range that are just outside our confidence interval.**

+ If you conclude that some of the autocorrelations are significantly different from 0, give an explanation why some autocorrelations are significantly different from zero. In particular, some lags beyond lag = 0 may appear significantly different from zero; discuss why this is the case, especially considering that `rand_ts` is by definition a totally random time series.

**The one at lag = 0 is significantly different simply because there is nothing before it. For the ones after, a totally random time series could still generate points with possible correlation because of its randomness.**

b. (12pts) Now we'll make autocorrelation plots using the NYC bike data. For this part, answer the following two questions.

+ (6pts) First, make an autocorrelation plot for the NYC bike data using `trips_per_day$n_trips` (which you should have defined in Problem 2). In particular, make two plots: One with the default lags 0 through 30, and another plot with lags 0 through 500. When making your plots, please display them in a 1 x 2 grid by using `par(mfrow = c(1,2))` before your two `acf()` lines of code.

```{r}
par(mfrow = c(1,2))
acf(trips_per_day$n_trips, lag.max = 30)
acf(trips_per_day$n_trips, lag.max= 500)
```

After you've made your plots, interpret them in 1-3 sentences. Be sure to interpret your plots within the context of this dataset, which is about bike rides.

**If we only lag by 30, we can see that there is a positive correlation, which makes sense - bike rides in the same season stay in the same range. However, if we increase lag to 500, we can see upwards and downwards trends of correlation, which also makes sense - the number of bike rides should correlate positively with its own season and conversely with opposite weather. These correlatoins are also almost all statistically significant.**

+ (6pts) Now, using `trips_per_day_usertype` (which you should have defined in Problem 2), create two autocorrelation plots of the `trips_per_day_usertype` time series, one for subscribers and one for customers. For both plots, display lags 0 through 500, and again arrange the plots in a 1 x 2 grid. Furthermore, when you make your plots, note that the axes for both plots are on different scales, which makes it more difficult to compare the plots; to make the axes the same, use `ylim = c(-0.3, 1)` within the `acf()` function.

```{r}
par(mfrow = c(1,2))
acf(subset(trips_per_day_usertype, usertype == "Customer")$n_trips, lag.max = 500, ylim = c(-0.3, 1))
acf(subset(trips_per_day_usertype, usertype == "Subscriber")$n_trips, lag.max = 500, ylim = c(-0.3, 1))
```

After you've made your plots, compare and contrast them in 1-3 sentences. Again, be sure to interpret your plots within the context of this dataset.

**There seems to be higher autocorrelations within customers (left) as compared to subscribers (right). Furthermore, there does not seem to be any lag for subscribers around the 400 range, which does not hold true for customers. A reason may be because the pandemic affected long-term commitments to going outside, but something of lower commitment was not affected as much.**

***
***

## Problem 4: Moving Averages (26 points)

a. (16pts) Now we'll visualize moving averages for the NYC bike dataset. For this part, make a moving average plot for the `trips_per_day` dataset. You'll need to install (and load) the `ggseas` library to do this. Your plot should use the functions `ggplot()`, `geom_line()`, and `stat_rollapplyr()`. Your plot should exhibit the following characteristics:

1) Your plot should display the raw time series (using `geom_line()`) as well as the moving average (using `statrollapplyr()`. Make sure the raw time series and moving average are different colors so that the plot is easier to read.

2) Within `stat_rollapplyr()`, set `align = "left"`, and choose a `width` that you think fits the data well and is interpretable for this dataset.

3) Interestingly, this dataset contains data on bike trips made both before and after the start of the COVID-19 pandemic. In particular, New York City started initiating shutdowns related to the pandemic on March 15, 2020. In your plot, use `geom_rect()` to create rectangular shading for all data that occurs after March 15, 2020; make sure that your shading does not extend beyond dates observed in the data. For the rectangular shading, use a color other than gray. (**Hint**: You'll have to make sure that you specify dates that follow the date format in the data. Specifically, within `as.Date()`, you'll have to specify `format` correctly. Look back at Problem 2B to see what we did to handle date formats.)

```{r}
library(ggseas)
ggplot(data = trips_per_day, aes(x = start.date, y = n_trips)) + 
geom_rect(xmin = as.Date("2020-03-15"), xmax = as.Date("2021-01-31"), ymin = 0, ymax = Inf, fill = "cadetblue1", alpha = 0.5) +
geom_line(color = "aliceblue") + 
stat_rollapplyr(color = "darkslategray3", width = 28, align = "left", alpha = 0.5) + 
ggtitle("Width = 28")
```

After you've made your plot, discuss in 1-2 sentences why you chose this particular `width` value for your plot. Then, in 1-2 sentences, discuss to what extent you think the time series changed soon after pandemic-related lockdowns started in New York City.

**I chose 28 because it neatly encapsulate four weeks, which is essentially a month. After pandemic-relation lockdowns started in New York, there was an initial drop in number of bike rides at first, with numerous drops afterwards that may signify more restrictions or new outbreaks. However, there is a huge spike near fall of 2020**.

b. (10pts) There is a whole literature on different moving averages; for example, we discussed weighted moving averages and cumulative moving averages in class. In this problem, we'll work with a special kind of weighted moving average that's commonly used in finance: an [exponential moving average](https://en.wikipedia.org/wiki/Moving_average#Exponential_moving_average) (EMA).

The idea of EMAs is to upweigh recent time periods and downweigh far away time periods when computing the moving average. In this part, you must compute the EMA in the `trips_per_day` dataset, and then plot that EMA on top of the raw time series. An EMA is defined in the following way:

+ For the first time period, $t = 1$, set $S_1 = Y_1$, where $S_t$ is the EMA at time point $t$, and $Y_t$ is the outcome at time point $t$ (in our case, `n_trips`).

+ For the next time periods ($t > 1$), define $S_t = \alpha Y_t + (1- \alpha) S_{t-1}$ for some constant $\alpha$. Typically, people set $\alpha = 2/(h + 1)$, where $h$ is the size of the window (i.e., the `width` you specified in Part A).

Luckily, `trips_per_day` should already be ordered by `start.date`, which will make computing the EMA easier. Below is some template code to get you started with computing the EMA; you must alter this code, based on the above methodology for computing the EMA:

```{r}
#first, define EMA in the dataset
trips_per_day$ema = vector(length = nrow(trips_per_day))
#initialize the first EMA
trips_per_day$ema[1] = trips_per_day$n_trips[1]

#define alpha
alpha = 2/(28 + 1) 
#define the remaining EMAs
for(i in 2:nrow(trips_per_day)){
  trips_per_day$ema[i] = alpha*(trips_per_day$n_trips[i]) + (1 - alpha)*(trips_per_day$ema[i-1])
}
```

After you've altered the above code such that `ema` is defined, create a plot with `n_trips` on the y-axis and `start.date` on the x-axis, as well as a line denoting the EMA. When making your plot, be sure that the raw time series and EMA are different colors. Also, please include the rectangular shading you used in Part A.

```{r}
ggplot(data = trips_per_day, aes(x = start.date, y = n_trips)) + 
geom_rect(xmin = as.Date("2020-03-15"), xmax = as.Date("2021-01-31"), ymin = 0, ymax = Inf, fill = "cadetblue1", alpha = 0.5) +
geom_line(color = "black") + 
geom_line(aes(y = ema), color = "red") + 
ggtitle("Red Line is EMA")
```

For this part, all you have to do is create the plot. You should end up with a moving average that looks similar to the kind of moving averages you might see for stock prices.

***
***

## Problem 5: Seasonal Decompositions (16 points)

Finally, we'll consider seasonal decompositions for the NYC bike dataset. For this part, answer the following two questions.

+ (8pts) Using the `ggsdc()` function in the `ggseas` library, create a seasonal decomposition plot for the `trips_per_day` dataset. Within the `ggsdc` function, there are two arguments, `frequency` and `s.window`. The `frequency` argument is basically the same as the `width` argument in the `stat_rollapplyr()` function, so set `frequency` equal to the value you set `width` to in Problem 4. Meanwhile, set `s.window = 7`. (Thinking more deeply about what to set `s.window` to is outside the scope of this class, but I encourage final project teams working with time series data to think about it.)

```{r}
ggsdc(trips_per_day, aes(x = start.date, y = n_trips), frequency = 28,s.window = 7, method = "stl") + geom_line() + 
labs(x = "Date", y = "No. of Trips")
```

After you've made your plot, interpret it in 1-4 sentences. In particular, be sure to discuss each of the four plots provided by the `ggsdc()` function.

**The observed plot shows our observed data points. The trend graph shows the general trend of n_trips as time passes. Seasonal shows the difference in n_trips and its general variation over time. Irregular describes the residuals of the observed data points.**

+ (8pts) Now make a seasonal decomposition plot for the `trips_per_day_usertype` dataset, with lines colored by `usertype`. Within `geom_line()`, set `alpha` equal to something less than 1 to make it easier to see all the lines. If you've made your plot successfully, the top plot should basically be the same plot you made in Problem 2C.

```{r}
ggsdc(trips_per_day_usertype, aes(x = start.date, y = n_trips, color = usertype), frequency = 28,s.window = 7, method = "stl") + 
geom_line(alpha = 0.5) + 
labs(x = "Date", y = "No. of Trips")
```

After you've made your plot, interpret the **last two plots** in the seasonal decomposition plot in 1-3 sentences. (We'll hold off on interpreting the first two plots, especially because you already interpreted the first plot in Problem 2C.)

**Based on the last two plots, there seems to be a lot more initial variations with subscribers pre-COVID, but more variations with customers post-COVID.**

***
***
***



