---
title: "36-315 Homework 11, Fall 2022"
author: "Alex Cheng"
date: "Due Wednesday, December 7, 2022 (11:59pm ET) on Gradescope"
output:
  pdf_document:
    toc: yes
urlcolor: blue
---

#  Homework 11: Word Clouds, TF-IDF Weighting, Sentiment Analyses, and Topic Modeling for Visualizing Text Data

***General instructions for all assignments***: 

+ Use this file as the template for your submission. Be sure to write your name at the top of this page in the author section.

+ Please write out your answers in *italics* or **bold** to differentiate your answers from the problem statements. (However, your code does not needed to be italicized or bold, of course!)

+ For your homework submission, generate an .html file and an .Rmd file (named as: [AndrewID]-315-Homework11.Rmd -- e.g. "zbranson-315-Homework11.Rmd"). When you're done, submit it to Gradescope (the link to the course's Gradescope can be found on Canvas). Remember that Gradescope only accepts PDFs, so be sure to Knit to PDF (see Lab0). Alternatively, you can use [this online converter](https://cloudconvert.com/html-to-pdf) to convert your HTML file to a PDF. If you have trouble knitting to PDF, please contact the Head TA and Professor Branson.

+ Your file should contain the code to answer each question in its own code block. Your code should produce plots/output that will be automatically embedded in the PDF. **Before submitting your PDF, be sure that all of your code/plots are displayed.**

+ Each answer must be supported by written statements (unless otherwise specified). **Thus, even if you think your code output is self-explanatory, be sure to answer questions with written statements outside of code blocks.**

+ Although it's okay to discuss homework problems with other students, all of your homework (code, written answers, etc.) should be only your own. Instances of identical, nearly identical, or copied homework will be considered cheating and plagiarism. In other words, you must follow rules of academic integrity (as detailed in the syllabus).

***
***

# Problem 1: Working on Your Group Project (15pts)

Similar to the last homework, this homework is a bit shorter so that you have time to work on your final project. Remember that you have the following due dates for the final project:

+ **Monday, December 12 by 12pm**: A publicly-available HTML file. Knit via RStudio, but write your file for the public.
+ **Tuesday/Wednesday, December 13-14**: 12-to-15-minute presentations (via Zoom) followed by 5-to-8-minute Q\&A.
+ **Friday, December 16 by 12pm**: A final written report (should include text and graphs; the report should be 5-10 pages excluding graphs).

Be sure to read the rubric for the final group project that I posted on Canvas a while back (Files/Final Project). That's exactly what we will use to evaluate final projects---I hope this makes expectations for the final project clear. Email me if you have any questions/concerns.

For this problem, using the dataset for your final project, make one of the following types of graphs:

+ A dendrogram, PCA-based, or MDS-based plot.
+ A graph related to spatial data (e.g., a choropleth map, heat map, or other map-type graphic).
+ A graph related to time series data (e.g., a moving average, an autocorrelation plot, etc.)
+ A text-related plot (e.g., a word cloud, top TF-IDF words, a sentiment analysis graph, etc.)

I'm pinpointing these graphs because (as explained in the rubric), you must make at least one of these types of graphs (as well as EDA, as you did in Homework10) for your final project. If you already made one of the above types of graphs for Homework10, please make a new graph for this homework.

Make sure your graph is properly labeled such that it is clear what you are displaying. Also, after you've made a graph you're happy with, take the time to share your graph with your team so they know what you've done so far. For this part, just include your graph and write 2-4 sentences discussing why you think your graph is informative/relevant for your final project.

```{r}
library(tidyverse)
df = read.csv("Rat_Population_DataAnalysis/Raw/rats_condensed.csv")
```
```{r}
#this is to clean the data, since we want to remove time stamps
library(stringr)
df$Created.Date = word(df$Created.Date, 1)
df = mutate(df, Created.Date = as.Date(Created.Date, format = "%m/%d/%Y"))
#now, we want to focus on brooklyn
df = subset(df, Borough = "MANHATTAN")
```
```{r}
library(ggseas)
rats_per_day = df %>% group_by(Created.Date) %>% tally()
ggplot(data = rats_per_day, aes(x = Created.Date, y = n)) + 
geom_rect(xmin = as.Date("2017-03-13"), xmax = as.Date("2019-10-01"), ymin = 0, ymax = Inf, fill = "blanchedalmond", alpha = 0.5) +
geom_rect(xmin = as.Date("2018-04-17"), xmax = Inf, ymin = 0, ymax = Inf, fill = "bisque4", alpha = 0.5) +
geom_line(color = "cadetblue") + 
stat_rollapplyr(color = "red", width = 14, align = "left", alpha = 0.5) + 
ggtitle("Width = 14")
```

**My graph describes the moving averages of the number of rats seen per day in Manhattan, with the window being around two-weeks. I then created two squares - the beige one symbolizes when [ContraPest was released in New York](https://www.prnewswire.com/news-releases/senestech-launches-new-york-city-sales-for-contrapest-rodent-control-solution-300422361.html), and the brown one represents when [De Blasio started his expensive campaign against rats](https://www.nyc.gov/office-of-the-mayor/news/195-18/mayor-de-blasio-targets-rats-extermination-10-nycha-developments#/0). I wanted to see if any of these campaigns were effective in slowing down the rat sightings, and obviously it wasn't as the graph actually went up.**

#  Problem 2: Processing Text Data from Reddit (20 points)

```{r global options, include = FALSE}
knitr::opts_chunk$set(warning=FALSE, message=FALSE)
```

In this homework we will work with text data. `R` packages for text data often produce many messages and warnings that create messy HTML files when you Knit. To suppress these warnings, I added some `knitr` code above this paragraph in the .Rmd file such that messages and warnings aren't printed out in any of the `R` code you submit for this homework (you'll have to look at the .Rmd file to see what I mean). **When making your HTML files for the final project, you should suppress warnings and messages in this way - otherwise, you'll have a very messy HTML file that's meant for the public!**

In ongoing research, I've been studying gender disparities in online forums - e.g., do men, women, and non-binary people communicate differently online? And more importantly, are they treated differently? My collaborators and I have been focusing on reddit.com. For those not familiar with reddit.com (hereafter called Reddit), I will give a brief description here. Reddit is a website where users anonymously submit posts – questions, jokes, recipes, memes, gifs, and many other things – and other users reply with “upvotes”, “downvotes”, and comments. Within Reddit, there are many “subreddits,” which are basically subforums dedicated to particular topics.

Gender disparities are difficult to assess on Reddit because it is anonymous, and thus we usually do not know users’gender. However, on the /r/relationships subreddit – where users ask for advice about relationships (which could be romantic, platonic, professional, etc.) – it is very common for users to “declare” their gender. In this way, the /r/relationships subreddit is uniquely different from most other parts of Reddit. For example, someone may make a post with the title, “My [25F] roommate [24M] refuses to do the dishes.” In this case, the poster has “declared” that they are a 25-year-old female with a 24-year-old male roommate. My collaborators and I downloaded every text-based Reddit post ever made, focused on the /r/relationships subreddit, and algorithmically labeled each post as being made by a “male” or “female” author (or at least the ones that had a [F] or [M] label, like in the aforementioned example).

A limitation of this approach is that it excludes Reddit users who may not identify as male or female; at the time my collaborators and I weren't aware of a common label (like [F] and [M]) for non-binary, and we focused on a binary view of gender for simplicity. For the sake of this homework we will view gender in a binary fashion, but I wanted to acknowledge the limitation of this perspective. Another limitation is that we will believe that Reddit users are telling the truth about their gender identity (e.g., someone who posts as [F] truly identifies as female). [But do we really think someone would just go on the Internet and tell lies?](https://www.youtube.com/watch?v=YWdD206eSv0)

In this homework, you will focus on a random set of 20,000 posts from this subreddit. Here's the dataset:
```{r, message = FALSE, warning = FALSE}
library(tidyverse)
data = read.csv("https://raw.githubusercontent.com/zjbranson/315Fall2021/main/redditData.csv", encoding = "UTF-8")
```

The main variables we'll focus on in this homework are:

+ `title`: The text of the title of each post.
+ `gender`: The gender of each poster. For simplicity, we are focusing on male and female posters.

The URL of each post is also available in the dataset, if you're curious what these posts are about (however, this is not necessary for you to look at for this homework). Note that some of these posts are explicit, so read at your own discretion.

a. (10pts) If you haven't already done so, install the `tm` library. To get you started, the following line of code recodes the `title` column into a `Corpus`, which is necessary to use the functions in the `tm` library:
```{r, message = FALSE, warning = FALSE}
library(tm)
title = Corpus(VectorSource(data$title))
```
Using the `tm_map()` function, change all the titles to lowercase, remove punctuation, and remove extra white space.

```{r}
title = tm_map(title, content_transformer(tolower))
title = tm_map(title, removePunctuation)
title = tm_map(title, stripWhitespace)
```

After you've done this, answer the following questions:

+ Create a Document-Term Matrix of the titles using the `DocumentTermMatrix()` function. How many unique terms are in the resulting matrix?

```{r}
title.dtm = DocumentTermMatrix(title)
ncol(title.dtm)
```

**8323**

+ Use the `DocumentTermMatrix()` function again, but this time, remove stopwords and perform stemming. Call this matrix `dtm.title`. How many unique terms are in the resulting matrix?

```{r}
dtm.title = DocumentTermMatrix(title, control = list(stopwords = TRUE, stemming = TRUE))
ncol(dtm.title)
```

**6166**

+ Using the Document-Term Matrix you just made, `dtm.title`, what are the top ten most frequent words? Please display these words from most frequent to least frequent. For this task, you just need to write code that outputs the top ten words; you don't need to make a graph.

```{r}
freq = colSums(as.matrix(dtm.title))
freq = sort(freq, decreasing = TRUE)
head(freq,10)
```

b. (10pts) Let's look at word usage for males and females. First, create two subsets of the data: one that contains only "male" posts and one that contains "female" posts. Then, for each subset, convert the titles to a `Corpus` object, just like I did in Part A. Call these `Corpus` objects `title.male` and `title.female`, respectively.

```{r}
males = subset(data, gender == "M")
females = subset(data, gender == "F")
title.male = Corpus(VectorSource(males$title))
title.female = Corpus(VectorSource(females$title))

```

After you've done that, repeat the preprocessing from Part A (change all the titles to lowercase, remove punctuation, and remove extra white space) for `title.male` and `title.female`. After preprocessing, create a Document-Term Matrix (removing stopwords and performing stemming) for `title.male` and `title.female`.

```{r}
title.male = tm_map(title.male, content_transformer(tolower))
title.male = tm_map(title.male, removePunctuation)
title.male = tm_map(title.male, stripWhitespace)

title.female = tm_map(title.female, content_transformer(tolower))
title.female = tm_map(title.female, removePunctuation)
title.female = tm_map(title.female, stripWhitespace)

dtm.mal = DocumentTermMatrix(title.male, control = list(stopwords = TRUE, stemming = TRUE))
dtm.fem = DocumentTermMatrix(title.female, control = list(stopwords = TRUE, stemming = TRUE))
```

After you've done that, answer the following questions:

+ How many documents and unique terms are in the male posts subset? How about the female posts subset?

```{r}
nrow(dtm.mal)
ncol(dtm.mal)
nrow(dtm.fem)
ncol(dtm.fem)
```

**Male posts: 5153 documents, 4172 terms. Female posts: 4847 documents, 4234 terms.**

+ What are the top ten most frequent words for males? What about for females? Please display these words from most frequent to least frequent. Then, compare and contrast these two top-ten lists of words.

```{r}
malefreq = colSums(as.matrix(dtm.mal))
malefreq = sort(malefreq, decreasing = TRUE)
head(malefreq,10)

femfreq = colSums(as.matrix(dtm.fem))
femfreq = sort(femfreq, decreasing = TRUE)
head(femfreq,10)
```

**The words are very similar, with most of the words being exactly the same and almost in the same order. They both are also indecisive about pursuing a relationship with the words "feel", "dont", "know", but men focus on girlfriends and girls focus on boyfriends. Furthermore, there seem to be a lot of 22 year old women who are on the subreddit posting.**

# Problem 3: Word Clouds (30 points)

a. (8pts) In Problem 2A, you should have made a Document-Term matrix called `dtm.title`, where you removed stop words and performed stemming after processing the data using `tm_map()`. In this problem, you'll use `dtm.title` to make a word cloud of frequently used words in Reddit post titles.

After loading the `wordcloud` library, use `dtm.title` to make a word cloud of the Reddit titles using the `wordcloud()` function. When using this function, specify the following arguments:

+ `words`
+ `freq`
+ `max.words`
+ `random.order`
+ `colors`
+ `rot.per`

For the above arguments, choose specifications that you think make the word cloud look good (i.e., visually pleasing and interpretable).

```{r}
library(wordcloud)
reddit.words = colnames(dtm.title)
reddit.freqs = colSums(as.matrix(dtm.title))
wordcloud(words = reddit.words, freq = reddit.freqs, random.order = FALSE, max.words = 100, rot.per = 0.3,colors = c("chartreuse", "cornflowerblue", "darkorange"))
```

After you've made your word cloud, in 1-2 sentences, make some observations about the word cloud (there aren't necessarily specific "right" answers here - just mention what stands out to you).

**Year is always very prominent since ages are very important in this subreddit to provide context. Most of the titles are about relationships with their significant others, but there are also other titles such as families and sisters.**

**Hints**: In Problem 2A, you should have already computed `words` and `freq` (the first two arguments). Details about the next three arguments are discussed in the R demo. Finally, we haven't talked about the last argument (`rot.per`), so look at the help documentation (`help(wordcloud)`) to understand what this argument does.

b. (10pts) In Problem 2B, you should have made a Document-Term matrix for male posts specifically and a Document-Term matrix for female posts specifically, where you removed stop words and performed stemming after processing the data using `tm_map()`. Using those Document-Term matrices, make a word cloud for male posts and a word cloud for female posts. Similar to Part A, choose specifications for the arguments of `wordcloud()` that make these word clouds visually pleasing to you. Arrange these word clouds in a 1x2 grid using `par(mfrow=c(1,2))`. When you Knit, you may find that the world clouds aren't fully displayed; if this is the case for you, set `fig.width = 10` within "{r}" when writing your code for the wordcloud (i.e., write `{r, fig.width = 10}` instead).

```{r}
par(mfrow=c(1,2))
mal.words = colnames(dtm.mal)
mal.freqs = colSums(as.matrix(dtm.mal))
wordcloud(words = mal.words, freq = mal.freqs, random.order = FALSE, max.words = 100, rot.per = 0.3,colors = c("cadetblue1", "red", "violet"))
fem.words = colnames(dtm.fem)
fem.freqs = colSums(as.matrix(dtm.fem))
wordcloud(words = fem.words, freq = fem.freqs, random.order = FALSE, max.words = 100, rot.per = 0.3,colors = c("chartreuse", "cornflowerblue", "darkorange"))
```

After you've made your word clouds, compare and contrast the word clouds in 1-2 sentences.

**The main words reflect what we see in the top ten words that we generated in the previous task. However, there seems to be a lot more emphasis on women's ages compared to mens, and a lot more general confusion on the men's side.**

c. (12pts) Now let's make a comparison word cloud to compare word usage for male and female posts. To get you started, the following code combines `title.male` and `title.female` into one `Corpus`, converts the Corpus to a plain text document, and then computes a Term-Document Matrix. **Before running this code, be sure that you have already properly defined `title.male` and `title.female` in Problem 2B.** (I considered asking you to write this code yourself, but I thought, "It's the last homework---why not give these students a break?")
```{r}
#put the male and female titles into one corpus
titleMaleFemale = tm:::c.VCorpus(title.male, title.female)
titleMaleFemale = tm_map(titleMaleFemale, PlainTextDocument)

#remove stop words, perform stemming
titleMaleFemale = tm_map(titleMaleFemale, removeWords, stopwords("english"))
titleMaleFemale = tm_map(titleMaleFemale, stemDocument)
```

Now we will create a TF-IDF weighted comparison word cloud. For this part, please complete the following **three tasks**:

+ First, create a *Term-Document matrix* using `titleMaleFemale` (defined above). *When defining this Term-Document matrix, use TF-IDF weighting.* Define this weighted Term-Document matrix as `tdm_maleFemale`. Then, convert your Term-Document matrix to a typical matrix by writing `tdm_maleFemale = as.matrix(tdm_maleFemale)` after `tdm_maleFemale` is appropriately defined.

```{r}
tdm_maleFemale = TermDocumentMatrix(titleMaleFemale, control = list(weighting = weightTfIdf))
tdm_maleFemale = as.matrix(tdm_maleFemale)
```

+ Now make a comparison word cloud using `tdm_maleFemale`. To do this, you'll have to create a new matrix with just two columns: The first column sums the word counts across all male documents, and the other column does the same for female documents, where the rows correspond to the individual words in the Term-Document matrix. Call this matrix `tdm_maleFemale_sum`, and run `colnames(tdm_maleFemale_sum) = c("Male" ,"Female")` to change the column names of this matrix. Then, use `tdm_maleFemale_sum` and `comparison.cloud()` to create a comparison world cloud for male and female posts. Note that we went through a very similar process in lecture and the R demo. Similar to Part A, choose specifications for the arguments of `comparison.cloud()` that make this word cloud visually pleasing to you.

```{r}
tdm_male_sum = rowSums(tdm_maleFemale[,1:5153])
tdm_female_sum = rowSums(tdm_maleFemale[,5154:10000])
tdm_maleFemale_sum = cbind(tdm_male_sum, tdm_female_sum)
colnames(tdm_maleFemale_sum) = c("Male" ,"Female")
comparison.cloud(tdm_maleFemale_sum, random.order = FALSE,
colors = c("blue", "red"), max.words = 100)
```

+ After you've made your comparison word cloud, interpret it in 1-3 sentences. In particular, compare and contrast the language that male and female posters tend to use on this subreddit.

**The language they use is very similar, often relating to ages and feelings of each person. Furthermore, it is often very emotionally charged language.**

# Problem 4: Sentiment Analysis (25 points)

Now we will examine what types of "positive" and "negative" words men and women use on Reddit.

a. (10pts) In Problem 2B, you should have defined the unique words used by men and women and the frequencies of those words. Create a data.frame called `maleTitle.df` with the unique words (for males) in one column and their frequencies in another column. Also create an analogous data.frame called `femaleTitle.df` for females.

```{r}
maleTitle.df = as.data.frame(malefreq)
femaleTitle.df = as.data.frame(femfreq)
maleTitle.df = rownames_to_column(maleTitle.df)
femaleTitle.df = rownames_to_column(femaleTitle.df)
names(maleTitle.df) = c("word", "count")
names(femaleTitle.df) = c("word", "count")
```

After doing this, install the `tidytext` R package (if you haven't already done so), and define a data.frame that contains (1) the unique words (for males) in one column, their frequencies in another column, and (3) whether the word is "positive" or "negative" based on the Bing dictionary. Similarly define a data.frame for females. The datasets you define below should have much fewer rows than `maleTitle.df` or `femaleTitle.df`, because only a subset of the words in these datasets will be in the Bing dictionary.
```{r}
library(tidytext)
library(tidyverse)
maleTitle.df = maleTitle.df %>% inner_join(get_sentiments("bing"))
femaleTitle.df = femaleTitle.df %>% inner_join(get_sentiments("bing"))
```

Using these data frames, answer the following questions:

+ What is the total frequency of positive and negative words for males? What is the total frequency of positive and negative words for females?

```{r}
sum(subset(maleTitle.df, sentiment=="positive")$count)
sum(subset(maleTitle.df, sentiment=="negative")$count)
sum(subset(femaleTitle.df, sentiment=="positive")$count)
sum(subset(femaleTitle.df, sentiment=="negative")$count)
```

**Male positive: 1536, negative: 3179. Female positive: 1482, negative: 2877**

+ Is the proportion of positive words (compared to negative words) significantly different between males and females? Answer this question using a statistical test.

```{r}
prop.test(c(1536,1482), c(4715,4359))
```

**The p-value is high (0.1574 compared to 0.05), so we fail to reject the null hypothesis. There is insufficient evidence that the proportions are not equal.**

**Hint**: For the second bullet point, I could be mean and say, "You should have learned this in a previous stats class, so why should I give you any hints??" But the semester is almost over and we're all tired so here's a hint. Use the `prop.test()` function. This function takes two arguments: `x` and `n`. `x` is the vector of "number of successes", and `n` is the vector of "number of trials". Thus, if `x` and `n` are vectors of length 2 (one number for males, one number for females), then `prop.test()` will test if the proportion of successes is different between the two groups. So, think carefully what `x` and `n` should be for this problem; in particular, imagine going through each word and labeling it as either positive (a "success") or negative (not a "success").

b. (15pts) Regardless of whether or not men and women have significantly different proportions of positive words, they may be using different kinds of positive and negative words, so we are going to assess that here.

Make (1) a word cloud of the *positive* words that males use, and (2) a word cloud of the *positive* words that females use. Put these two word clouds side-by-side using `par(mfrow=c(1,2))`. Repeat this for `negative` words. Again, you may have to write `{r, fig.width = 10}` so that your word clouds fully display when you Knit your file. (Thus, your submission should have four word clouds, corresponding to the different positive/negative and male/female combinations.)

```{r, fig.width = 10}
par(mfrow=c(1,2))
male_positive = subset(maleTitle.df, sentiment=="positive")
wordcloud(words = male_positive$word, freq = male_positive$count, random.order = FALSE, colors=brewer.pal(8, "Paired"), max.words = 100)

female_positive = subset(femaleTitle.df, sentiment=="positive")
wordcloud(words = female_positive$word, freq = female_positive$count, random.order = FALSE, colors=brewer.pal(8, "Paired"), max.words = 100)
```

From these plots, do you think males and females are using the same kinds of positive and negative words? Explain in 1-2 sentences.

**Yes, since the biggest words are almost identical, as well as the medium sized words.**

**Hint**: Use the data frames you defined in Part A.

# Problem 5: Topic Modeling (10 points)

For this problem, install the `topicmodels` `R` package.

In Problem 2A, you should have defined an object called `dtm.title`. (This is the Document-Term Matrix of titles, after preprocessing, removing stop words, and performing stemming.) Using this Document-Term matrix, perform the following tasks:

+ First, using the `LDA()` function, run latent Dirichlet allocation (i.e., topic modeling) with k = 2 topics. To make sure you always get the same topic modeling results, within `LDA()`, set `control = list(seed = 1234)`.

```{r}
library(topicmodels)
title_lda <- LDA(dtm.title, k = 2, control = list(seed = 1234))
```

+ Now recall that, within a topic model, there are *word probabilities* associated with each topic. For each of the two topics, make a bar plot of the top ten word probabilities. In other words, you should make two bar plots (one for each topic), where one axis displays the top ten words, and the other axis displays their corresponding probabilities within that topic. You can choose whether the x- or y-axis corresponds to the probabilities (i.e., whether the probabilities should correspond to the width or height of the bars). For this part, you just need to make the plot---just be sure that it's clear which plot corresponds to the first topic, and which corresponds to the second topic. (**Hint**: We discussed this type of plot for topic models in class, so you may want to revisit your lecture notes if you're unsure what kind of plot to make here.)

```{r}

library(ggplot2)
library(dplyr)
library(tidytext)

titles = tidy(title_lda, matrix = "beta")
titles_top_terms <- titles %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)


titles_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip() +
scale_x_reordered()
```

+ After you've produced the graph from the code below: Do the two topics produced by LDA seem distinct/different? If not, this may suggest that all titles in this dataset are really just about one topic. Does this make sense, given the context of this dataset? Explain your answer in 1-3 sentences.

**The two garphs do not seem very different, and all seem to really be about dating and romance. However,for some reason the men also mention boyfriends, which may attest to either gay men or a third party involved.**


***
***
***



